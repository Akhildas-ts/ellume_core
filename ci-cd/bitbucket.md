# âœ… Letâ€™s Start â€” Your pipeline has only 2 parts

1.  **definitions** = the reusable step
2.  **pipelines** = when to run the step

So weâ€™ll start with definitions.

---

## ðŸ§© PART 1 â€” definitions

This creates a reusable block called `build-and-deploy-service`.

```yaml
definitions:
  steps:
    - step: &build-and-deploy-service
```

ðŸ‘‰ **Meaning:**
You are creating a step template named `build-and-deploy-service`.
Later you will call it using `<<: *build-and-deploy-service`.

### ðŸ³ The environment for this step

```yaml
image: gcr.io/google.com/cloudsdktool/cloud-sdk:slim
services:
    - docker
```

ðŸ‘‰ **Meaning:**
*   Use a Google Cloud SDK image (so you get `gcloud` command)
*   Enable Docker engine inside the pipeline â†’ because you will build Docker images

### ðŸ“¦ script: The actual things the pipeline does

Everything inside the `script`: runs step-by-step.

#### ðŸ”µ STEP 1 â€” Basic setup

```bash
SERVICE_NAME="ellume-core"
ENV_NAME=$(echo "$BITBUCKET_DEPLOYMENT_ENVIRONMENT" | tr '[:upper:]' '[:lower:]')
```

ðŸ‘‰ **Meaning:**
*   Name of the Cloud Run service = `ellume-core`
*   Convert environment â†’ lowercase (Development â†’ development, Production â†’ production)

#### ðŸ”µ STEP 2 â€” Validate environment

```bash
if [ "$BITBUCKET_DEPLOYMENT_ENVIRONMENT" != "development" ] &&
    [ "$BITBUCKET_DEPLOYMENT_ENVIRONMENT" != "production" ] &&
    [ "$BITBUCKET_DEPLOYMENT_ENVIRONMENT" != "staging" ]; then
  echo "Invalid DEPLOYMENT..."
  exit 1
fi
```

ðŸ‘‰ **Meaning:**
Only allow development, staging, production.
If someone tries to deploy other environment â†’ **STOP**.

#### ðŸ”µ STEP 3 â€” Check if all required secrets exist

```bash
required_secrets=(
  "SA_BUILD_DEPLOY"
  "PROJECT_ID"
  "REGION"
  "SERVER_PORT"
  "JWT_SECRET"
  "ARTIFACT_REGISTRY_URL"
  "DATABASE_DRIVER"
  "DATABASE_DSN"
  "CLOUDSQL_INSTANCE"
)
```

ðŸ‘‰ **Meaning:**
Pipeline needs these secrets. If any missing â†’ deployment fails.

Then this loop checks one by one:

```bash
for secret in "${required_secrets[@]}"; do
  if [ -z "${!secret}" ]; then
    missing_secrets+=("$secret")
  fi
done
```

ðŸ‘‰ **Meaning:**
*   `${!secret}` = get value of secret name (Example: `PROJECT_ID` â†’ get its value)
*   If missing â†’ add to `missing_secrets`.
*   If any missing â†’ print them â†’ exit.

#### ðŸ”µ STEP 4 â€” Authenticate to Google Cloud

```bash
echo "${SA_BUILD_DEPLOY}" | base64 -d > ${HOME}/gcp-key.json
gcloud auth activate-service-account --key-file ${HOME}/gcp-key.json
gcloud config set project $PROJECT_ID
gcloud auth configure-docker $REGION-docker.pkg.dev --quiet
```

ðŸ‘‰ **Meaning:**
1.  Decode service account key
2.  Login to Google Cloud
3.  Set the correct project
4.  Allow Docker to push images to Artifact Registry

Your pipeline now has access to GCP.

#### ðŸ”µ STEP 5 â€” Build Docker image with 3 tags

```bash
BUILD_TIME=$(date -u +'%Y-%m-%dT%H:%M:%SZ')
BUILD_TIMESTAMP=$(date -u +'%s')
```

ðŸ‘‰ **Meaning:**
*   Build time in ISO format
*   Build time as UNIX timestamp

Now create 3 image tags:

```bash
LATEST_TAG="...:development-latest"
DATED_TAG="...:development-commitHash"
VERSION_TAG="...:development-timestamp"
```

ðŸ‘‰ **Why 3 tags?**
*   `latest` â†’ newest version
*   `commit` â†’ helps rollback
*   `timestamp` â†’ exact build

Now build:

```bash
docker build \
   --tag "$LATEST_TAG" \
   --tag "$DATED_TAG" \
   --tag "$VERSION_TAG" \
   --build-arg GITHUB_SHA="$BITBUCKET_COMMIT" \
   --build-arg GITHUB_REF="$BITBUCKET_BRANCH" \
   --build-arg BUILD_TIME="$BUILD_TIME" \
   --build-arg BUILD_ENVIRONMENT="$ENV_NAME" \
   .
```

ðŸ‘‰ **Meaning:**
You build ONE image but tag it 3 different ways.
Also pass build info into Dockerfile.

#### ðŸ”µ STEP 6 â€” Push images to Artifact Registry

```bash
docker push "$LATEST_TAG"
docker push "$DATED_TAG"
docker push "$VERSION_TAG"
```

ðŸ‘‰ **Meaning:**
Upload all 3 versions to GCP registry.

#### ðŸ”µ STEP 7 â€” Deploy to Cloud Run

```bash
DEPLOY_IMAGE="${ARTIFACT_REGISTRY_URL}/${SERVICE_NAME}:${ENV_NAME}-latest"
```

ðŸ‘‰ **Meaning:**
Cloud Run always uses the latest image for that environment.

Then:

```bash
gcloud run deploy ellume-core \
   --image="$DEPLOY_IMAGE" \
   --region=$REGION \
   --platform=managed \
   --allow-unauthenticated \
   --port=$SERVER_PORT \
   --project=$PROJECT_ID \
   --add-cloudsql-instances=$CLOUDSQL_INSTANCE \
   --set-env-vars=ENVIRONMENT=$ENV_NAME,...
```

ðŸ‘‰ **Meaning:**
You tell Cloud Run:
*   which image to deploy
*   which GCP region
*   which port to expose
*   which SQL instance to connect
*   which environment variables to set

Cloud Run now:
1.  pulls image
2.  replaces previous version
3.  publishes new URL

#### ðŸ”µ STEP 8 â€” Cleanup

```bash
rm -f ${HOME}/gcp-key.json
```

ðŸ‘‰ **Meaning:**
Delete the service account key for security.

---

## ðŸŸ¢ PART 2 â€” pipelines

```yaml
pipelines:
  branches:
    new_dev:
      - step:
          <<: *build-and-deploy-service
          deployment: Development
```

ðŸ‘‰ **Meaning:**
Whenever you push code to `new_dev` branch:
1.  Use the reusable step (`<<: *build-and-deploy-service`)
2.  Set environment = `Development`

And then the whole script runs for development.

---

## ðŸŽ‰ Super Simple Summary With Code Sense

Here is what your pipeline does in order, using the code you pasted:

1.  Set `SERVICE_NAME` + `ENV_NAME`
2.  Check environment is valid
3.  Check required secrets exist
4.  Login to Google Cloud
5.  Build Docker image with 3 tags
6.  Push all 3 tags to Artifact Registry
7.  Deploy the latest tag to Cloud Run
8.  Clean temporary GCP key
